{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, lossType = \"MSE\"):\n",
    "        self.lossType = lossType \n",
    "    \n",
    "    def backwardPass(self, X, Y):\n",
    "        if(self.lossType == \"MSE\"):\n",
    "            return self.backwardPassMSE(X, Y)\n",
    "        elif(self.lossType == \"CE\"):\n",
    "            return self.backwardPassCE(X,Y)\n",
    "        return\n",
    "    \n",
    "    def forwardPass(self, X, Y):\n",
    "        if(self.lossType == \"MSE\"):\n",
    "            return self.forwardPassMSE(X, Y)\n",
    "        elif(self.lossType == \"CE\"):\n",
    "            return self.forwardPassCE(X,Y)\n",
    "        return\n",
    "   \n",
    "    def forwardPassMSE(X, Y):\n",
    "        return ((X-Y).T)@(X-Y)*0.5\n",
    "    \n",
    "    def forwardPassCE(X, Y):\n",
    "        return -np.sum(Y*np.log(X))\n",
    "   \n",
    "    def backwardPassMSE(P, Y):\n",
    "        return P-Y\n",
    "    \n",
    "    def backwardPassCE(P,Y):\n",
    "        # dl_dx = -dl_dn * (Y/X);\n",
    "        return Y/P\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def __init__(self, act = \"linear\"):\n",
    "        self.act = act \n",
    "    \n",
    "    def backwardPass(self, X):\n",
    "        if(self.lossType == \"linear\"):\n",
    "            return self.backwardPassLinear(X)\n",
    "        elif(self.lossType == \"sigmoid\"):\n",
    "            return self.backwardPassSigmoid(X)\n",
    "        return\n",
    "    \n",
    "    def forwardPass(self, X):\n",
    "        if(self.lossType == \"linear\"):\n",
    "            return self.forwardPassLinear(X)\n",
    "        elif(self.lossType == \"sigmoid\"):\n",
    "            return self.forwardPassSigmoid(X)\n",
    "        return\n",
    "   \n",
    "    def forwardPassLinear(X):\n",
    "        return X\n",
    "    \n",
    "    def forwardPassSigmoid(X):\n",
    "        return 1/(1 + np.exp(-X))\n",
    "   \n",
    "    def backwardPassLinear(P):\n",
    "        return 1\n",
    "    \n",
    "    def backwardPassSigmoid(self, P):\n",
    "        return self.forwardPassSigmoid(P) * (1 - self.forwardPassSigmoid(P))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, numNeurons = 1, numNeuronsPrev = 1, act = \"linear\", alpha = 1e-5):\n",
    "        # Neurons in the current layer\n",
    "        self.numNeurons = numNeurons\n",
    "        # Neurons in the previous layer\n",
    "        self.numNeuronsPrev = numNeuronsPrev\n",
    "        # Weights for linear sum\n",
    "        self.W = np.random.rand(numNeurons, numNeuronsPrev)\n",
    "        # Bias of size Nx1\n",
    "        self.B = np.random.rand(numNeurons, 1)\n",
    "        # Activation function \n",
    "        self.activation = Activation(act)\n",
    "        self.alpha = alpha\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def update(self, dl_dw, dl_db):\n",
    "        self.W -= self.alpha*(dl_dw)\n",
    "        self.B -= self.alpha*(dl_db)\n",
    "    def forwardPasslinear(self, X):\n",
    "        self.input = X\n",
    "        return (self.W)@X + (self.B)\n",
    "    \n",
    "    def forwardPass(self, X):\n",
    "        arg = self.forwardPasslinear(X)\n",
    "        return self.activation.forwardPass(arg)\n",
    "    \n",
    "    def backwardPasslinear(self, dl_ds):\n",
    "        # dl_dx = np.zeros((dl_dw.shape[1], 1))\n",
    "        dl_dx = self.W.T@dl_ds\n",
    "        dl_dw = (dl_ds@(self.input).T)\n",
    "        return (dl_dx, dl_dw)\n",
    "    \n",
    "    def backwardPass(self, dl_dh):\n",
    "        # dl_ds where S = W@X + B\n",
    "        dl_ds = dl_dh*self.activation.backwardPass(self.forwardPasslinear(self.input))  \n",
    "        dl_dx, dl_dw = self.backwardPasslinear(dl_ds)\n",
    "\n",
    "        self.update(dl_dw, dl_ds)\n",
    "        return dl_dx\n",
    "\n",
    "        # fw= self.forwardPasslinear(self.input)\n",
    "        # dl_dx = dl_dh * (self.activation.backwardPass(fw))\n",
    "        # return self.backwardPasslinear(dl_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, listLayers = [], str = \"MSE\", inp = np.zeros((10,5)), pred = np.ones((10,1))):\n",
    "        self.listLayers = listLayers\n",
    "        self.lossObj = Loss(str)\n",
    "        self.target = pred\n",
    "        # Input data to the neural network\n",
    "        self.input = inp\n",
    "    \n",
    "    def forwardPassNN(self, i, Y):\n",
    "        R = self.listLayers[i].forwardPass(Y)\n",
    "        return R\n",
    "\n",
    "    def run(self):\n",
    "        for d in range(len(self.inp)):\n",
    "            Y = self.inp[d].reshape(self.inp.shape[1], 1)\n",
    "            for i in range(len(self.listLayers)):\n",
    "                Y = self.forwardPassNN(i, Y)\n",
    "            \n",
    "            targ = self.target[d].reshape(self.target.shape[1],1)\n",
    "            myLoss = self.lossObj.forwardPass(Y, self.target[d])\n",
    "            dl_dh = self.lossObj.backwardPass(Y, self.target[d])\n",
    "            for i in range(len(self.listLayers) -1, -1, -1):\n",
    "                dl_dh = self.listLayers[i].backwardPass(dl_dh)\n",
    "    \n",
    "    def test(self, dataPts, targets):\n",
    "        accuracy = 0 \n",
    "        for ind in range(len(dataPts)):\n",
    "            Y = dataPts[ind]\n",
    "            for i in range(len(self.listLayers)):\n",
    "                Y = self.forwardPassNN(i)\n",
    "            \n",
    "            if Y.item() == targets[ind]:\n",
    "                accuracy += 1\n",
    "        print(100*(accuracy/len(dataPts)))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "Y = raw_df.values[1::2, 2]\n",
    "Y = Y.reshape((Y.shape[0],1))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
